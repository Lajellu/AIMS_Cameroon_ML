{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Lab06","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"0HkA4LT9vXyi","outputId":"10a11876-4c26-4ce1-b633-55e9484f7b43"},"source":["import keras\n","keras.__version__"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.0.8'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"3f8MdzPavXyt"},"source":["# 5.1 - Introduction to convnets\n","\n","This notebook contains the code sample found in Chapter 5, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n","\n","----\n","\n","First, let's take a practical look at a very simple convnet example. We will use our convnet to classify MNIST digits, a task that you've already been \n","through in Chapter 2, using a densely-connected network (our test accuracy then was 97.8%). Even though our convnet will be very basic, its \n","accuracy will still blow out of the water that of the densely-connected model from Chapter 2.\n","\n","The 6 lines of code below show you what a basic convnet looks like. It's a stack of `Conv2D` and `MaxPooling2D` layers. We'll see in a \n","minute what they do concretely.\n","Importantly, a convnet takes as input tensors of shape `(image_height, image_width, image_channels)` (not including the batch dimension). \n","In our case, we will configure our convnet to process inputs of size `(28, 28, 1)`, which is the format of MNIST images. We do this via \n","passing the argument `input_shape=(28, 28, 1)` to our first layer.\n","\n","Write the 6 lines of code using the comments below. Write a line of code wherever you see #..."]},{"cell_type":"code","metadata":{"id":"oGsfF_-jvXyu"},"source":["from keras import layers\n","from keras import models\n","\n","# 1. Instantiate a Sequential object from the models library. No parameters.\n","model = #...\n","\n","# 2. Add a Conv2D layer to the model. \n","# Use 32 filters, a 3x3 kernel size, activation type=’relu’ and an input shape of 28 x 28 x 1. \n","# Search for the “layers.Conv2D” function online and use only the parameters just mentioned. \n","model.add(#...)\n","\n","# 3. Add a MaxPooling2D layer with pool_size=(2, 2). \n","# Search for the “layers.MaxPooling2D function online and use only the pool_size parameter\n","model.add(#...)\n","\n","# 4. Add a Conv2D layer to the model. \n","# Use 64 filters, a 3x3 kernel size, and activation type=’relu’. \n","# Search for the “layers.Conv2D” function online and use only the parameters just mentioned. \n","model.add(#...)\n","\n","# 5. Add a MaxPooling2D layer with pool_size=(2, 2). \n","# Search for the “layers.MaxPooling2D function online and use only the pool_size parameter\n","model.add(#...)\n","\n","# 6. // Add a Conv2D layer to the model. \n","# Use 64 filters, a 3x3 kernel size, and activation type=’relu’. \n","# Search for the “layers.Conv2D” function online and use only the parameters just mentioned. \n","model.add(#...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwJ1uJdJvXyu"},"source":["Let's display the architecture of our convnet so far:"]},{"cell_type":"code","metadata":{"id":"tmVHvMmJvXyv","outputId":"9a090cc9-b2e3-4e7c-dd2b-cd9a4266f95b"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n","=================================================================\n","Total params: 55,744\n","Trainable params: 55,744\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"wCkh1wYEvXyv"},"source":["You can see above that the output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width \n","and height dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to \n","the `Conv2D` layers (e.g. 32 or 64).\n","\n","The next step would be to feed our last output tensor (of shape `(3, 3, 64)`) into a densely-connected classifier network like those you are \n","already familiar with: a stack of `Dense` layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. \n","So first, we will have to flatten our 3D outputs to 1D, and then add a few `Dense` layers on top. \n","\n","Write 3 lines of code using the comments below:"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Cp4Y9sLZvXyw"},"source":["# 1. Add a Flatten layer, no parameters needed\n","model.add(#...)\n","\n","# 2. Add a Dense layer with 64 units, and relu activation function\n","model.add(#...)\n","\n","# 3. Add a Dense layer with 10 units, and softmax activation function\n","model.add(#...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57pj_NdavXyx"},"source":["We are going to do 10-way classification, so we use a final layer with 10 outputs and a softmax activation. Now here's what our network \n","looks like:"]},{"cell_type":"code","metadata":{"id":"gRP6P9RdvXyx","outputId":"f67a8636-e4bc-4724-8d51-67380611c054"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 576)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                36928     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3fiifP7NvXyy"},"source":["As you can see, our `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two `Dense` layers.\n","\n","Now, let's train our convnet on the MNIST digits. We will reuse a lot of the code we have already covered in the MNIST example from Chapter \n","2.\n","\n","Write X lines of code in the second code block below, using the comments. "]},{"cell_type":"code","metadata":{"id":"29peE-Z7vXyy"},"source":["from keras.datasets import mnist\n","from keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype('float32') / 255\n","\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype('float32') / 255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esXio8XvvXyy","outputId":"e45d4426-ae7b-4c1c-b512-ddfe2cf4b807"},"source":["# Compile the model with rmsprop optimizer, categorical crossentropy as the loss function, and accuracy as the metric.\n","model.compile(#...)\n","\n","# Train the model using the model.fit() with the training images, training labels, 5 epochs, and a batch size of 64\n","model.fit(#...)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 8s - loss: 0.1766 - acc: 0.9440     \n","Epoch 2/5\n","60000/60000 [==============================] - 7s - loss: 0.0462 - acc: 0.9855     \n","Epoch 3/5\n","60000/60000 [==============================] - 7s - loss: 0.0322 - acc: 0.9902     \n","Epoch 4/5\n","60000/60000 [==============================] - 7s - loss: 0.0241 - acc: 0.9926     \n","Epoch 5/5\n","60000/60000 [==============================] - 7s - loss: 0.0187 - acc: 0.9943     \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbd9c4cd828>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"sLRgcSAjvXyz"},"source":["Let's evaluate the model on the test data:"]},{"cell_type":"code","metadata":{"id":"aW_QyiODvXyz","outputId":"93b0aa39-a8a2-4d35-8fe9-c12696cc7bce"},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 9536/10000 [===========================>..] - ETA: 0s"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iZEHCj4TvXyz","outputId":"21d96b75-cea2-4026-ec5b-f67802bcdf02"},"source":["test_acc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.99129999999999996"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"G-NpE0zxvXy0"},"source":["While our densely-connected network from Chapter 2 had a test accuracy of 97.8%, our basic convnet has a test accuracy of 99.3%: we \n","decreased our error rate by 68% (relative). Not bad! "]},{"cell_type":"markdown","metadata":{"id":"hPcu3iHTx8v7"},"source":["---\n","\n","##Lab Questions\n","* **Question 1**:  What kind of data would you use Conv Net with? (1 Mark)\n","```\n","Your answer here\n","```\n","\n","* **Question 2**: Do some research about Filters and Feature Maps. What are they used for in a Conv Net? (3 Marks)\n","```\n","Your answer here\n","```\n","* **Question 3**: How does the max pooling layer work? How does it conserve computional power? (2 Marks)\n","```\n","Your answer here\n","```\n","* **Question 4**:  In point form, in your own words, summarize the contents of this research paper: https://arxiv.org/pdf/1511.08458.pdf. Don’t worry, it’s not overly technical, and just try to focus on the big picture. (1 Page)\n"," (15 Marks)\n","```\n","Your answer here\n","```\n","* **Question 5**: Consider the implications of training face recognition AI on only humans with Nordic descent. (1 Paragraph)\n","** a)  What biases would this AI have when trying to detect humans with Cameroon descent? \n","** b) Consider a world where cameras monitor everyone’s actions and you are automatically sent fines to your mail when your face is recognized to have done something against the law. What legal issues could these biases in the face recognition system cause? \n","(5 Marks)\n","*\n","```\n","Your answer here\n","```\n","\n"]}]}